{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 树回归\n",
    "- 优点：可以对复杂和非线性的数据建模。\n",
    "- 缺点：结果不易理解。\n",
    "- 适用数据类型：数值型和标称型数据\n",
    "#### ID3\n",
    "- ID3的做法是每次选取当前最佳的特征来分割数据，并按照该特征的所有可能取值来切分。\n",
    "- 存在问题：切分过于迅速；不能直接处理连续型特征。\n",
    "#### 树回归的一般方法：\n",
    "（1）收集数据：可以使用任意方法。  \n",
    "（2）准备数据：需要数值型数据，标称型数据将被转成二值型数据。  \n",
    "（3）分析数据：绘出数据的可视化二维图将有助于对数据做出理解和分析，以字典方式生成树。  \n",
    "（4）训练算法：大部分时间都花费在叶节点树模型的构建上。  \n",
    "（5）测试算法：使用测试数据上的R2来分析模型的效果。  \n",
    "（6）使用算法：使用训练出的树做预测，预测结果还可以用来做很多事情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "函数说明:加载函数\n",
    "\n",
    "Parameters:\n",
    "    fileName - 文件名\n",
    "Returns:\n",
    "    dataMat- 数据集\n",
    "\"\"\"\n",
    "def loadDataSet(fileName):\n",
    "    dataMat = []\n",
    "    fr = open(fileName)     #打开文件\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split('\\t')  #读取以tab键为分隔符的文件\n",
    "        fltLine = list(map(float,curLine))    #将每一行的内容保存成一组浮点数\n",
    "        dataMat.append(fltLine)\n",
    "    return dataMat      #返回数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:切分函数\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "    feature - 待切分的特征\n",
    "    value - 待切分特征的某个值\n",
    "Returns:\n",
    "    mat0 - 切分好的子集\n",
    "    mat1 - 切分好的子集\n",
    "\"\"\"\n",
    "def binSplitDataSet(dataSet, feature, value):\n",
    "    #当使用布尔数组直接作为下标对象或者元组下标对象中有布尔数组时，\n",
    "    # 都相当于用nonzero()将布尔数组转换成一组整数数组，然后使用整数数组进行下标运算。\n",
    "    mat0 = dataSet[np.nonzero(dataSet[:, feature] > value)[0], :]\n",
    "    mat1 = dataSet[np.nonzero(dataSet[:, feature] <= value)[0], :]\n",
    "    return mat0,mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:生成叶节点\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "Returns:\n",
    "    目标变量特征的均值\n",
    "\"\"\"\n",
    "def regLeaf(dataSet):\n",
    "    return np.mean(dataSet[:,-1])\n",
    "\n",
    "\"\"\"\n",
    "函数说明:误差估计函数\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "Returns:\n",
    "    目标变量的平方误差\n",
    "\"\"\"\n",
    "def regErr(dataSet):\n",
    "    return np.var(dataSet[:,-1])*np.shape(dataSet)[0]\n",
    "\"\"\"\n",
    "函数说明:找到数据的最佳二元切分方式\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "    leafType - 建立叶节点函数\n",
    "    errType - 误差计算函数\n",
    "    ops - 树构建所需其他参数\n",
    "Returns:\n",
    "    bestIndex - 最好的特征索引\n",
    "    bestValue - 最好的特征切分值\n",
    "\"\"\"\n",
    "def chooseBestSplit(dataSet, leafType=regLeaf, errType = regErr, ops=[1,4]):\n",
    "    tolS = ops[0]   #容许的误差下降值\n",
    "    tolN = ops[1]   #切分的最少样本数\n",
    "    if len(set(dataSet[:,-1].T.tolist()[0]))==1:    #倒数第一列转化成list 不重复，则无需切分\n",
    "        return None,leafType(dataSet)   # 找不到好的切分特征，调用regLeaf直接生成叶结点\n",
    "    m,n = np.shape(dataSet)\n",
    "    S = errType(dataSet)    #计算平方误差\n",
    "    bestS = np.inf; bestIndex = 0; bestValue = 0\n",
    "    for featIndex in range(n-1):    #遍历数据的每个属性特征\n",
    "        for splitVal in set((dataSet[:,featIndex].T.A.tolist())[0]): #遍历每个特征里不同的特征值\n",
    "            mat0, mat1 = binSplitDataSet(dataSet, featIndex, splitVal)  #对每个特征进行二元分类\n",
    "            if (np.shape(mat0)[0]<tolN) or (np.shape(mat1)[0]<tolN): continue   #如果低于规定的切分最少样本数，则跳过本次循环\n",
    "            newS = errType(mat0)+errType(mat1)\n",
    "            if newS < bestS:    #更新为误差最小的特征\n",
    "                bestIndex = featIndex\n",
    "                bestValue = splitVal\n",
    "                bestS = newS\n",
    "    if(S - bestS) < tolS:   #如果切分后误差效果下降不大，则取消切分，直接创建叶结点\n",
    "        return None, leafType(dataSet)\n",
    "    mat0,mat1 = binSplitDataSet(dataSet, bestIndex, bestValue)\n",
    "    # 判断切分后子集大小，小于最小允许样本数停止切分3\n",
    "    if (np.shape(mat0)[0] < tolN) or (np.shape(mat1)[0] < tolN):\n",
    "        return None,leafType(dataSet)\n",
    "    return bestIndex,bestValue  #返回特征索引和用于切分的特征值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:树的构建函数\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "    leafType - 建立叶节点函数\n",
    "    errType - 误差计算函数\n",
    "    ops - 树构建所需其他参数\n",
    "Returns:\n",
    "    retTree- 构建好的树\n",
    "\"\"\"\n",
    "def createTree(dataSet, leafType=regLeaf, errType=regErr, ops=(1,4)):\n",
    "    feat,val = chooseBestSplit(dataSet, leafType, errType, ops) #切分数据集\n",
    "    if feat == None: return val #满足停止条件则返回叶节点值\n",
    "    retTree = {}\n",
    "    retTree['spInd'] = feat\n",
    "    retTree['spVal'] = val\n",
    "    lSet,rSet = binSplitDataSet(dataSet, feat, val)\n",
    "    retTree['left'] = createTree(lSet, leafType, errType, ops)  #递归调用\n",
    "    retTree['right'] = createTree(rSet, leafType, errType, ops)\n",
    "    return retTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spInd': 0,\n",
       " 'spVal': 0.48813,\n",
       " 'left': 1.0180967672413792,\n",
       " 'right': -0.044650285714285719}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat = loadDataSet('data\\ex00.txt')\n",
    "myMat = np.mat(myDat)\n",
    "retTree = createTree(myMat)\n",
    "retTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过降低决策树的复杂度来避免过拟合的过程称为剪枝。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:测试输入变量是否是一棵树\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "Returns:\n",
    "    是否是一棵树\n",
    "\"\"\"\n",
    "def isTree(obj):\n",
    "    return (type(obj).__name__=='dict')\n",
    "\n",
    "\"\"\"\n",
    "函数说明:返回树的平均值\n",
    "\n",
    "Parameters:\n",
    "    tree - 树\n",
    "Returns:\n",
    "    树的平均值\n",
    "\"\"\"\n",
    "def getMean(tree):\n",
    "    if isTree(tree['right']): tree['right'] = getMean(tree['right'])\n",
    "    if isTree(tree['left']): tree['left'] = getMean(tree['left'])\n",
    "    return (tree['right']+tree['left'])/2.0\n",
    "\n",
    "\"\"\"\n",
    "函数说明:树的后剪枝\n",
    "\n",
    "Parameters:\n",
    "    tree - 待剪枝的树\n",
    "    testData - 剪枝所需测试数据\n",
    "Returns:\n",
    "    tree- 剪枝好的树\n",
    "\"\"\"\n",
    "def prune(tree, testData):\n",
    "    if np.shape(testData)[0] == 0: return getMean(tree)     #判断测试数据是否为空\n",
    "    # 假设发生过拟合，采用测试数据对树进行剪枝\n",
    "    if (isTree(tree['right']) or isTree(tree['left'])):     #左右子树非空\n",
    "        lSet, rSet = binSplitDataSet(testData, tree['spInd'], tree['spVal'])    #对测试数据生成树\n",
    "    if isTree(tree['left']): tree['left'] = prune(tree['left'],lSet)    #判断左分支是否为树，若是，则调用剪枝函数进行剪枝\n",
    "    if isTree(tree['right']): tree['right'] = prune(tree['right'], rSet)#判断右分支是否为树，若是，则调用剪枝函数进行剪枝\n",
    "    # 剪枝后判断是否还是有子树\n",
    "    if not isTree(tree['left']) and not isTree(tree['right']):\n",
    "        lSet, rSet = binSplitDataSet(testData, tree['spInd'], tree['spVal'])\n",
    "        # 判断是否merge\n",
    "        errorNoMerge = np.sum(np.power(lSet[:,-1]-tree['left'],2))+np.sum(np.power(rSet[:,-1]-tree['right'],2))\n",
    "        treeMean = (tree['left']+tree['right'])/2.0\n",
    "        errorMerge = np.sum(np.power(testData[:,-1]-treeMean,2))\n",
    "        # 如果合并后误差变小\n",
    "        if errorMerge < errorNoMerge:\n",
    "            print(\"merging\")\n",
    "            return treeMean\n",
    "        else: return tree\n",
    "    else: return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 模型树的可解释性是它优于回归树的特点之一。另外，模型树也具有更高的预测准确度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:模型树\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "Returns:\n",
    "    ws - 回归系数\n",
    "    X - 自变量X\n",
    "    Y - 目标变量Y\n",
    "\"\"\"\n",
    "def linearSolve(dataSet):\n",
    "    m,n = np.shape(dataSet)\n",
    "    X = np.mat(np.ones((m,n))); Y = np.mat(np.ones((m,1)))\n",
    "    X[:,1:n] = dataSet[:,0:n-1]; Y = dataSet[:,-1]  #将数据集格式化为X,Y\n",
    "    xTx = X.T*X\n",
    "    if np.linalg.det(xTx) == 0.0:   #X,Y应用简单线性回归求得回归系数ws\n",
    "        raise NameError(\"This matrix is singular, cannon do inverse,\\n\"\n",
    "                        \"try increasing the second value of ops\")\n",
    "    ws = xTx.I*(X.T*Y)\n",
    "    return ws,X,Y\n",
    "\n",
    "\"\"\"\n",
    "函数说明:生成叶节点的模型\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "Returns:\n",
    "    ws - 回归系数\n",
    "\"\"\"\n",
    "def modelLeaf(dataSet):\n",
    "    ws,X,Y = linearSolve(dataSet)\n",
    "    return ws\n",
    "\n",
    "\"\"\"\n",
    "函数说明:在给定的数据集上计算误差\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "Returns:\n",
    "    误差\n",
    "\"\"\"\n",
    "def modelErr(dataSet):\n",
    "    ws,X,Y = linearSolve(dataSet)\n",
    "    yHat = X*ws\n",
    "    return np.sum(np.power(Y-yHat,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例：树回归与标准回归的比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "函数说明:回归树叶节点预测\n",
    "\n",
    "Parameters:\n",
    "    model - 数据集\n",
    "    inDat - 原数据矩阵\n",
    "Returns:\n",
    "    预测值\n",
    "\"\"\"\n",
    "def regTreeEval(model, inDat):\n",
    "    return float(model)\n",
    "\n",
    "\"\"\"\n",
    "函数说明:模型树叶节点预测\n",
    "\n",
    "Parameters:\n",
    "    model - 数据集\n",
    "    inDat - 原数据矩阵\n",
    "Returns:\n",
    "    预测值\n",
    "\"\"\"\n",
    "def modelTreeEval(model, inDat):\n",
    "    n = np.shape(inDat)[1]\n",
    "    X = np.mat(np.ones((1,n+1)))    #在原数据矩阵上增加第0列\n",
    "    X[:,1:n+1] = inDat\n",
    "    return float(X*model)   #计算并返回预测值\n",
    "\n",
    "\"\"\"\n",
    "函数说明:预测\n",
    "\n",
    "Parameters:\n",
    "    tree - 训练好的树\n",
    "    inDat - 待预测数据，单个数据点或行向量\n",
    "    modelEval - 树的类型\n",
    "Returns:\n",
    "    预测值\n",
    "\"\"\"\n",
    "def treeForeCast(tree, inData, modelEval=regTreeEval):\n",
    "    if not isTree(tree): return modelEval(tree,inData)\n",
    "    if inData[tree['spInd']] > tree['spVal']:\n",
    "        if isTree(tree['left']):\n",
    "            return treeForeCast(tree['left'],inData,modelEval)\n",
    "        else:\n",
    "            return modelEval(tree['left'],inData)\n",
    "    else:\n",
    "        if isTree(tree['right']):\n",
    "            return treeForeCast(tree['right'],inData,modelEval)\n",
    "        else:\n",
    "            return modelEval(tree['right'],inData)\n",
    "\n",
    "\"\"\"\n",
    "函数说明:以向量形式返回一组预测值\n",
    "\n",
    "Parameters:\n",
    "    tree - 训练好的树\n",
    "    testData - 待预测数据矩阵\n",
    "    modelEval - 树的类型\n",
    "Returns:\n",
    "    预测值\n",
    "\"\"\"\n",
    "def creatForeCast(tree, testData, modelEval = regTreeEval):\n",
    "    m = len(testData)   #测试数据的行数\n",
    "    yHat = np.mat(np.zeros((m,1)))\n",
    "    for i in range(m):\n",
    "        yHat[i,0] = treeForeCast(tree, np.mat(testData[i]), modelEval)\n",
    "    return yHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 创建一棵回归树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96408523182221495"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMat = np.mat(loadDataSet(\"data\\\\bikeSpeedVsIq_train.txt\"))\n",
    "testMat = np.mat(loadDataSet(\"data\\\\bikeSpeedVsIq_test.txt\"))\n",
    "myTree = createTree(trainMat,ops=(1,20))\n",
    "yHat = creatForeCast(myTree,testMat[:,0])\n",
    "np.corrcoef(yHat,testMat[:,1],rowvar=0)[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 创建一棵模型树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97604121913806285"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTree = createTree(trainMat,modelLeaf,modelErr, ops=(1, 20))\n",
    "yHat = creatForeCast(myTree, testMat[:, 0],modelTreeEval)\n",
    "np.corrcoef(yHat, testMat[:, 1], rowvar=0)[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 由上可得，模型树的结果比回归树的结果好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 标准线性回归效果如何?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94346842356747662"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws, X, Y = linearSolve(trainMat)\n",
    "for i in range(np.shape(testMat)[0]):\n",
    "    yHat[i]=testMat[i,0]*ws[1,0]+ws[0,0]\n",
    "np.corrcoef(yHat,testMat[:,1],rowvar=0)[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 树回归方法在预测复杂数据时会比简单的线性模型更有效。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
