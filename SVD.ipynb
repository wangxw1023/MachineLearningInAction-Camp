{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用SVD简化数据\n",
    "- 我们可以记录用户关于餐馆观点的数据进行处理，并且从中提取出其背后的因素。这些因素可能会与餐馆的类别、烹饪时所用的某个特定配料，或其他任意对象一致。然后我们可以利用这些因素来估计人们对没有去过的餐馆的看法。提取这些信息的方法称为奇异值分解（Singular Value Decomposition，SVD）.\n",
    "- 优点：简化数据，去除噪声，提高算法的结果。\n",
    "- 缺点：数据的转换可能难以理解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD的应用\n",
    "- 信息检索：称利用SVD的方法为隐性语义索引（Latent Semantic Indexing, LSI）或隐性语义分析（Latent Semantic Analysis，LSA）。在LSI中，一个矩阵由文档和词语组成。当我们在该矩阵上应用SVD时，就会构建出多个奇异值。这些奇异值代表了文档中的概念或主题，这一特点可以用于更高效的文档搜索。\n",
    "- 推荐系统：简单版本的推荐系统能够计算项或人之间的相似度。更先进的方法则先利用SVD从数据中构建一个主题空间，然后再在该空间下计算其相似度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵分解\n",
    "- 最常见的一种矩阵分解技术就是SVD。\n",
    "- SVD将原始的数据集$Data$分解成三个矩阵$U,Σ和V^T$，如果原始矩阵$Data$是m行n列，那么$U,Σ和V^T$就分别是m行m列，m行n列，n行n列。如下所示  \n",
    "$$Data_{m×n} = U_{m×m}Σ_{m×n}V^T_{n×n}$$\n",
    "- 矩阵$Σ$只有对角函数，其他函数均为零。并且它的对角函数是从大到小排列的。这些对角元素成为奇异值（Singular Value）。他们对应了原始数据集矩阵$Data$的奇异值。\n",
    "- SVD得到的是矩阵的奇异值，而PCA得到的是矩阵的特征值，其实奇异值和特征值是有关系的。这里的奇异值就是矩阵$Data*Data^T$特征值的平方根。\n",
    "- 在科学和工程中，一直存在这样一个普遍事实：在某个奇异值的数目（r个）之后，其他的奇异值都置为0。这就意味着数据集中仅有r个重要特征，而其他的特征则都是噪声或者冗余特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14142136, -0.98994949],\n",
       "       [-0.98994949,  0.14142136]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "U,Sigma,VT = np.linalg.svd([[1,1],[7,7]])\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+01,   2.82797782e-16])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678, -0.70710678],\n",
       "       [ 0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadExData():\n",
    "    return[[0, 0, 0, 2, 2],\n",
    "           [0, 0, 0, 3, 3],\n",
    "           [0, 0, 0, 1, 1],\n",
    "           [1, 1, 1, 0, 0],\n",
    "           [2, 2, 2, 0, 0],\n",
    "           [5, 5, 5, 0, 0],\n",
    "           [1, 1, 1, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = loadExData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,Sigma,VT = np.linalg.svd(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.64365076e+00,   5.29150262e+00,   6.51609210e-16,\n",
       "         2.14818942e-16,   5.18511491e-17])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sig3=np.mat([[Sigma[0], 0, 0], [0, Sigma[1], 0], [0, 0, Sigma[2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ -4.37395897e-16,   1.04047305e-15,   1.22370145e-15,\n",
       "           2.00000000e+00,   2.00000000e+00],\n",
       "        [ -6.64717157e-16,   3.85916933e-16,   2.78800224e-16,\n",
       "           3.00000000e+00,   3.00000000e+00],\n",
       "        [ -1.99303530e-16,   1.22205100e-16,   7.70984294e-17,\n",
       "           1.00000000e+00,   1.00000000e+00],\n",
       "        [  1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          -7.27982527e-17,  -7.16286297e-17],\n",
       "        [  2.00000000e+00,   2.00000000e+00,   2.00000000e+00,\n",
       "          -1.15127656e-16,  -1.11630659e-16],\n",
       "        [  5.00000000e+00,   5.00000000e+00,   5.00000000e+00,\n",
       "           4.54084131e-17,   4.34259903e-17],\n",
       "        [  1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          -5.75638278e-17,  -5.58153296e-17]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[:, :3]*Sig3*VT[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于协同过滤的推荐引擎\n",
    "- 有很多方法可以实现推荐功能，这里我们只使用一种称为协同过滤（collaborative filter）的方法。\n",
    "- 我们不利用专家所给出的重要属性来描述物品从而计算它们之间的相似度，而是利用用户对它们的意见来计算相似度。这就是协同过滤中所使用的方法。\n",
    "- 计算相似度的三种方法：欧式距离，相似度=1/(1+距离)；皮尔逊相关系数（Pearson correlation）；余弦相似度（cosine similarity）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as la\n",
    "\n",
    "def ecludSim(inA,inB):\n",
    "    return 1.0/(1.0 + la.norm(inA - inB))\n",
    "\n",
    "def pearsSim(inA,inB):\n",
    "    if len(inA) < 3 : return 1.0\n",
    "    return 0.5+0.5*np.corrcoef(inA, inB, rowvar = 0)[0][1]\n",
    "\n",
    "def cosSim(inA,inB):\n",
    "    num = float(inA.T*inB)\n",
    "    denom = la.norm(inA)*la.norm(inB)\n",
    "    return 0.5+0.5*(num/denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12973190755680383"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myMat=np.mat(loadExData())\n",
    "ecludSim(myMat[:, 0], myMat[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecludSim(myMat[:, 0], myMat[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosSim(myMat[:, 0], myMat[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosSim(myMat[:, 0], myMat[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20596538173840329"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsSim(myMat[:, 0], myMat[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsSim(myMat[:, 0], myMat[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果用户的数目很多，那么我们可能倾向于使用基于物品相似度的计算方法，而不采用基于用户相似度的方法。\n",
    "- 对于大部分产品导向的推荐引擎而言，用户的数量往往大于物品的数量，即购买商品的用户数会多于出售的商品种类。\n",
    "- 通常用于推荐引擎评价的指标是称为最小均方根误差（Root Mean Squared Error，RMSE）的指标，它首先计算均方误差的平均值然后取其平均值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例：餐馆菜肴推荐引擎\n",
    "推荐未尝过的菜肴：\n",
    "- 推荐系统的工作过程是：给定一个用户，系统会为此用户返回N个最好的推荐菜。\n",
    "需要做到： \n",
    "- 寻找用户没有评级的菜肴，即在用户-物品矩阵中的0值；\n",
    "- 在用户没有评级的所有物品中，对每个物品预计一个可能的评级分数。\n",
    "- 对这些物品的评分从高到低进行排序，返回前N个物品。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standEst(dataMat, user, simMeas, item):\n",
    "    '''\n",
    "    计算在给定相似度计算方法的条件下，用户对物品的估计评分值。\n",
    "    - dataMat：数据矩阵\n",
    "    - user：用户编号\n",
    "    - simMeas：相似度计算方法\n",
    "    - item：物品编号\n",
    "    '''\n",
    "    n = np.shape(dataMat)[1]  #得到数据集中的物品数目\n",
    "    simTotal = 0.0; ratSimTotal = 0.0   #初始化后面用于计算估计评分值的变量\n",
    "    for j in range(n):    #遍历行中的每个物品\n",
    "        userRating = dataMat[user,j]    #用户评分\n",
    "        if userRating == 0: continue    #如果某个物品的评分为零，则意味着没有用户对该物品进行评分\n",
    "        overLap = np.nonzero(np.logical_and(dataMat[:,item].A>0, \\\n",
    "                                      dataMat[:,j].A>0))[0]    #给出两个物品当中已经被评分的那个元素\n",
    "        if len(overLap) == 0: similarity = 0    #如果两者没有任何重合元素，则相似度为0且中止本次循环。\n",
    "        else: similarity = simMeas(dataMat[overLap,item], \\\n",
    "                                   dataMat[overLap,j])    #如果存在重合的物品，则基于这些重合物品计算相似度。\n",
    "        print('the %d and %d similarity is: %f' % (item, j, similarity))\n",
    "        simTotal += similarity    #相似度不断累加\n",
    "        ratSimTotal += similarity * userRating    #每次计算还考虑相似度和当前用户评分的乘积\n",
    "    if simTotal == 0: return 0\n",
    "    else: return ratSimTotal/simTotal    #除以所有评分的综合，归一化，返回0到5之间的评分值，这些评分值则用于对预测值进行排序\n",
    "\n",
    "def recommend(dataMat, user, N=3, simMeas=cosSim, estMethod=standEst):\n",
    "    '''\n",
    "    推荐引擎，产生最高的N个推荐结果。\n",
    "    - dataMat：数据矩阵\n",
    "    - user：用户编号\n",
    "    - N：N个推荐结果\n",
    "    - simMeas：相似度计算方法\n",
    "    - estMethod：估计方法\n",
    "    '''\n",
    "    unratedItems = np.nonzero(dataMat[user,:].A==0)[1]    #给定的用户建立一个未评分的物品列表\n",
    "    if len(unratedItems) == 0: return 'you rated everything'     #如果不存在未评分物品，那么退出函数\n",
    "    itemScores = []\n",
    "    for item in unratedItems:    #在所有未评分物品上进行循环\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)    #调用estMethod来产生该物品的预测分\n",
    "        itemScores.append((item, estimatedScore))    #该物品的编号和估计得分值会放在一个元素列表中\n",
    "    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]    #排序，并返回结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[4, 4, 0, 2, 2],\n",
       "        [4, 0, 0, 3, 3],\n",
       "        [4, 0, 0, 1, 1],\n",
       "        [1, 1, 1, 2, 0],\n",
       "        [2, 2, 2, 0, 0],\n",
       "        [5, 5, 5, 0, 0],\n",
       "        [1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myMat=np.mat(loadExData())\n",
    "myMat[0,1]=myMat[0,0]=myMat[1,0]=myMat[2,0]=4\n",
    "myMat[3,3]=2\n",
    "myMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1 and 0 similarity is: 1.000000\n",
      "the 1 and 3 similarity is: 0.928746\n",
      "the 1 and 4 similarity is: 1.000000\n",
      "the 2 and 0 similarity is: 1.000000\n",
      "the 2 and 3 similarity is: 1.000000\n",
      "the 2 and 4 similarity is: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 2.5), (1, 2.0243290220056256)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(myMat, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1 and 0 similarity is: 1.000000\n",
      "the 1 and 3 similarity is: 0.309017\n",
      "the 1 and 4 similarity is: 0.333333\n",
      "the 2 and 0 similarity is: 1.000000\n",
      "the 2 and 3 similarity is: 0.500000\n",
      "the 2 and 4 similarity is: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 3.0), (1, 2.8266504712098603)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(myMat, 2, simMeas=ecludSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1 and 0 similarity is: 1.000000\n",
      "the 1 and 3 similarity is: 1.000000\n",
      "the 1 and 4 similarity is: 1.000000\n",
      "the 2 and 0 similarity is: 1.000000\n",
      "the 2 and 3 similarity is: 1.000000\n",
      "the 2 and 4 similarity is: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 2.5), (1, 2.0)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(myMat, 2, simMeas=pearsSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadExData2():\n",
    "    return[[0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 5],\n",
    "           [0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 3],\n",
    "           [0, 0, 0, 0, 4, 0, 0, 1, 0, 4, 0],\n",
    "           [3, 3, 4, 0, 0, 0, 0, 2, 2, 0, 0],\n",
    "           [5, 4, 5, 0, 0, 0, 0, 5, 5, 0, 0],\n",
    "           [0, 0, 0, 0, 5, 0, 1, 0, 0, 5, 0],\n",
    "           [4, 3, 4, 0, 0, 0, 0, 5, 5, 0, 1],\n",
    "           [0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 4],\n",
    "           [0, 0, 0, 2, 0, 2, 5, 0, 0, 1, 2],\n",
    "           [0, 0, 0, 0, 5, 0, 0, 0, 0, 4, 0],\n",
    "           [1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,Sigma,VT=la.svd(np.mat(loadExData2()))\n",
    "myMat=np.mat(loadExData2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.77075346,  11.40670395,  11.03044558,   4.84639758,\n",
       "         3.09292055,   2.58097379,   1.00413543,   0.72817072,\n",
       "         0.43800353,   0.22082113,   0.07367823])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sig2=Sigma**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487.7999999999995"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Sig2)*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378.8295595113579"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Sig2[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.50028912757932"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Sig2[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 该值高于总能量的90%，因此我们可以将一个11维的矩阵转换成一个3维的矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svdEst(dataMat, user, simMeas, item):\n",
    "    '''\n",
    "    对给定用户构建一个评分估计值\n",
    "    '''\n",
    "    n = np.shape(dataMat)[1]    #得到物品总数\n",
    "    simTotal = 0.0; ratSimTotal = 0.0    #初始化\n",
    "    U,Sigma,VT = la.svd(dataMat)    #进行了SVD分解\n",
    "    Sig4 = np.mat(np.eye(4)*Sigma[:4]) #建立对角矩阵\n",
    "    xformedItems = dataMat.T * U[:,:4] * Sig4.I  #构建转换后的物品\n",
    "    for j in range(n):    #与上述standEst类似\n",
    "        userRating = dataMat[user,j]\n",
    "        if userRating == 0 or j==item: continue\n",
    "        similarity = simMeas(xformedItems[item,:].T,\\\n",
    "                             xformedItems[j,:].T)\n",
    "        print('the %d and %d similarity is: %f' % (item, j, similarity))\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: return 0\n",
    "    else: return ratSimTotal/simTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0 and 3 similarity is: 0.490950\n",
      "the 0 and 5 similarity is: 0.484274\n",
      "the 0 and 10 similarity is: 0.512755\n",
      "the 1 and 3 similarity is: 0.491294\n",
      "the 1 and 5 similarity is: 0.481516\n",
      "the 1 and 10 similarity is: 0.509709\n",
      "the 2 and 3 similarity is: 0.491573\n",
      "the 2 and 5 similarity is: 0.482346\n",
      "the 2 and 10 similarity is: 0.510584\n",
      "the 4 and 3 similarity is: 0.450495\n",
      "the 4 and 5 similarity is: 0.506795\n",
      "the 4 and 10 similarity is: 0.512896\n",
      "the 6 and 3 similarity is: 0.743699\n",
      "the 6 and 5 similarity is: 0.468366\n",
      "the 6 and 10 similarity is: 0.439465\n",
      "the 7 and 3 similarity is: 0.482175\n",
      "the 7 and 5 similarity is: 0.494716\n",
      "the 7 and 10 similarity is: 0.524970\n",
      "the 8 and 3 similarity is: 0.491307\n",
      "the 8 and 5 similarity is: 0.491228\n",
      "the 8 and 10 similarity is: 0.520290\n",
      "the 9 and 3 similarity is: 0.522379\n",
      "the 9 and 5 similarity is: 0.496130\n",
      "the 9 and 10 similarity is: 0.493617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 3.3447149384692283), (7, 3.3294020724526971), (9, 3.328100876390069)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(myMat, 1, estMethod=svdEst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于SVD的图像压缩\n",
    "- 原始的图像大小是32×32=1024像素，我们能否使用更少的像素来表示这张图呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printMat(inMat, thresh=0.8):\n",
    "    '''\n",
    "    打印矩阵\n",
    "    由于矩阵中包含浮点数，因此必须定义浅色和深色。\n",
    "    当元素大于thresh时，打印1；小于阈值时，打印0\n",
    "    '''\n",
    "    for i in range(32):\n",
    "        for k in range(32):\n",
    "            if float(inMat[i,k]) > thresh:\n",
    "                print(1, end=''),\n",
    "            else: print(0, end=''),\n",
    "        print('') \n",
    "\n",
    "def imgCompress(numSV=3, thresh=0.8):\n",
    "    '''\n",
    "    图像压缩\n",
    "    基于给定的奇异值数目来重构图像\n",
    "    '''\n",
    "    myl = []    #初始化一个列表\n",
    "    for line in open('0_5.txt').readlines():    #打开文本文件，并从文件中以数值方式读入字符\n",
    "        newRow = []\n",
    "        for i in range(32):\n",
    "            newRow.append(int(line[i]))\n",
    "        myl.append(newRow)\n",
    "    myMat = np.mat(myl)\n",
    "    print(\"****original matrix******\")\n",
    "    printMat(myMat, thresh)\n",
    "    U,Sigma,VT = la.svd(myMat)\n",
    "    SigRecon = np.mat(np.zeros((numSV, numSV)))\n",
    "    for k in range(numSV):    #构建对角矩阵\n",
    "        SigRecon[k,k] = Sigma[k]\n",
    "    reconMat = U[:,:numSV]*SigRecon*VT[:numSV,:]\n",
    "    print(\"****reconstructed matrix using %d singular values******\" % numSV)\n",
    "    printMat(reconMat, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****original matrix******\n",
      "00000000000000110000000000000000\n",
      "00000000000011111100000000000000\n",
      "00000000000111111110000000000000\n",
      "00000000001111111111000000000000\n",
      "00000000111111111111100000000000\n",
      "00000001111111111111110000000000\n",
      "00000000111111111111111000000000\n",
      "00000000111111100001111100000000\n",
      "00000001111111000001111100000000\n",
      "00000011111100000000111100000000\n",
      "00000011111100000000111110000000\n",
      "00000011111100000000011110000000\n",
      "00000011111100000000011110000000\n",
      "00000001111110000000001111000000\n",
      "00000011111110000000001111000000\n",
      "00000011111100000000001111000000\n",
      "00000001111100000000001111000000\n",
      "00000011111100000000001111000000\n",
      "00000001111100000000001111000000\n",
      "00000001111100000000011111000000\n",
      "00000000111110000000001111100000\n",
      "00000000111110000000001111100000\n",
      "00000000111110000000001111100000\n",
      "00000000111110000000011111000000\n",
      "00000000111110000000111111000000\n",
      "00000000111111000001111110000000\n",
      "00000000011111111111111110000000\n",
      "00000000001111111111111110000000\n",
      "00000000001111111111111110000000\n",
      "00000000000111111111111000000000\n",
      "00000000000011111111110000000000\n",
      "00000000000000111111000000000000\n",
      "****reconstructed matrix using 2 singular values******\n",
      "00000000000000000000000000000000\n",
      "00000000000000000000000000000000\n",
      "00000000000001111100000000000000\n",
      "00000000000011111111000000000000\n",
      "00000000000111111111100000000000\n",
      "00000000001111111111110000000000\n",
      "00000000001111111111110000000000\n",
      "00000000011110000000001000000000\n",
      "00000000111100000000001100000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001100000000\n",
      "00000000001111111111111000000000\n",
      "00000000001111111111110000000000\n",
      "00000000001111111111110000000000\n",
      "00000000000011111111100000000000\n",
      "00000000000011111111000000000000\n",
      "00000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "imgCompress(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
